{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170639b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial import Delaunay\n",
    "from sklearn.decomposition import PCA\n",
    "from itertools import combinations\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "from collections import Counter\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import matplotlib.tri as mtri\n",
    "import matplotlib.cm as cm\n",
    "matplotlib.rcParams['figure.dpi'] = 360\n",
    "matplotlib.rcParams['text.usetex'] = True\n",
    "os.environ['PATH'] = '/Library/TeX/texbin:' + os.environ['PATH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b77c422",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate_pca_3d(df):\n",
    "    # use only the real points to calculate the PCA\n",
    "    coords_real = df[~df['RAN']][['X', 'Y', 'Z']].values\n",
    "\n",
    "    pca = PCA(n_components=3)\n",
    "    pca.fit(coords_real)  # only reals define the orientation\n",
    "\n",
    "    coords_all = df[['X', 'Y', 'Z']].values\n",
    "    coords_rotated = pca.transform(coords_all)\n",
    "\n",
    "    df_rot = df.copy()\n",
    "    df_rot[['PC1', 'PC2', 'PC3']] = coords_rotated\n",
    "    #df_rot['Angle rotation [°]'] = np.degrees(np.arccos(np.clip(pca.components_[0] @ [0, 0, 1], -1, 1)))\n",
    "\n",
    "    return df_rot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f46aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_r(df):\n",
    "    coords = df[['X', 'Y', 'Z']].values\n",
    "    is_data = ~df['RAN'].values\n",
    "\n",
    "    tri = Delaunay(coords)\n",
    "\n",
    "    #! adjacency list for neighbors\n",
    "    neighbors = {i: set() for i in range(len(coords))}\n",
    "    for simplex in tri.simplices:\n",
    "        for i, j in combinations(simplex, 2):\n",
    "            neighbors[i].add(j)\n",
    "            neighbors[j].add(i)\n",
    "\n",
    "    r = np.zeros(len(coords), dtype=float)\n",
    "    for i, nbrs in neighbors.items():\n",
    "        n_data = int(np.sum(is_data[list(nbrs)]))\n",
    "        n_rand = len(nbrs) - n_data\n",
    "        if (n_data + n_rand) > 0:\n",
    "            r[i] = (n_data - n_rand) / (n_data + n_rand)\n",
    "        else:\n",
    "            raise ValueError(f'No neighbors for point {i} in the triangulation.')\n",
    "\n",
    "    out = df.copy()\n",
    "    out['r'] = r\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746a8e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_r(df):\n",
    "    r = df['r'].values\n",
    "    conds = [(r >= -1.0) & (r <= -0.9),\n",
    "             (r > -0.9) & (r <= 0.0),\n",
    "             (r > 0.0) & (r <= 0.9),\n",
    "             (r > 0.9) & (r <= 1.0),]\n",
    "    choices = ['void', 'sheet', 'filament', 'knot']\n",
    "    df = df.copy()\n",
    "    df['TYPE'] = np.select(conds, choices, default='error')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc13dff5",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d303f272",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base file paths\n",
    "base_url_data = 'create_files/'\n",
    "base_url_rand = 'data_100_random/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e35f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_filenames = [f'{base_url_data}QSO_{i}_clustering_data.ecsv' for i in range(20)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6607404",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Structure to store the 100 df per rosette\n",
    "# df_typed_all[i][j] is the dataframe of rosette i with random j\n",
    "df_typed_all = [[None for _ in range(100)] for _ in range(20)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8845a5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(20), desc=\"Rosettas\"):\n",
    "    # Read real data only once per rosette\n",
    "    data_file = data_filenames[i]\n",
    "    data = pd.read_csv(data_file, comment='#', sep=r'\\s+', engine='python')\n",
    "    data['RAN'] = False\n",
    "    data['ROSETTE_ID'] = i\n",
    "\n",
    "    for j in range(100):\n",
    "        rand_file = f'{base_url_rand}QSO_{i}_clustering_random_{j}.ecsv'\n",
    "        rand = pd.read_csv(rand_file, comment='#', sep=r'\\s+', engine='python')\n",
    "        rand['RAN'] = True\n",
    "        rand['ROSETTE_ID'] = i\n",
    "\n",
    "        # Concatenate real and random numbers\n",
    "        df = pd.concat([data, rand], ignore_index=True)\n",
    "\n",
    "        # PCA rotation\n",
    "        df_rot = rotate_pca_3d(df)\n",
    "\n",
    "        # Calculate r and classify\n",
    "        df_r = compute_r(df_rot)\n",
    "        df_typed = classify_r(df_r)\n",
    "        df_typed_all[i][j] = df_typed  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66310e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To SAVE the result in a file and not have to recalculate it\n",
    "\"\"\"\n",
    "with open('df_typed_all.pkl', 'wb') as f:\n",
    "    pickle.dump(df_typed_all, f)\n",
    "\"\"\"\n",
    "\n",
    "# To READ the result and not have to recalculate it\n",
    "\n",
    "\"\"\"\n",
    "with open('df_typed_all.pkl', 'rb') as f:\n",
    "    df_typed_all = pickle.load(f)\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ad60dd",
   "metadata": {},
   "source": [
    "# For verify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c75232",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(data_filenames)):\n",
    "\n",
    "    rosetta_idx = i  # Rosetta \n",
    "    n_randoms_to_plot = 100 # random number\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "\n",
    "    # Real data (RAN == False)\n",
    "    df_real = df_typed_all[rosetta_idx][0]  # we use any random because the real data is the same\n",
    "    df_real = df_real[df_real['RAN'] == False]\n",
    "    plt.scatter(df_real['PC1'], df_real['PC2'], color='black', label='Data (real)', s=10)\n",
    "\n",
    "    # Randam data (RAN == True)\n",
    "    for j in range(n_randoms_to_plot):\n",
    "        df_rand = df_typed_all[rosetta_idx][j]\n",
    "        if df_rand is not None:\n",
    "            df_rand = df_rand[df_rand['RAN'] == True]\n",
    "            plt.scatter(df_rand['PC1'], df_rand['PC2'], alpha=0.3, s=8)\n",
    "\n",
    "    plt.xlabel('PC1 [Mpc]')\n",
    "    plt.ylabel('PC2 [Mpc]')\n",
    "    plt.title(f'Rosetta {rosetta_idx}: Real vs 10 random samples')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e07e9c",
   "metadata": {},
   "source": [
    "# Type classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e188b757",
   "metadata": {},
   "outputs": [],
   "source": [
    "structure_types = ['void', 'sheet', 'filament', 'knot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7f07cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_fractions = {i: {t: [] for t in structure_types} for i in range(20)} # RAN == False\n",
    "rand_fractions = {i: {t: [] for t in structure_types} for i in range(20)} # RAN == True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4592a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(20):  # Rosettas\n",
    "    for j in range(100):  # Randoms\n",
    "        df = df_typed_all[i][j]\n",
    "\n",
    "        for source, container in [(False, data_fractions), (True, rand_fractions)]:\n",
    "            df_sub = df[df['RAN'] == source]\n",
    "            total = len(df_sub)\n",
    "\n",
    "            for t in structure_types:\n",
    "                count = np.sum(df_sub['TYPE'] == t)\n",
    "                frac = count / total if total > 0 else 0.0\n",
    "                container[i][t].append(frac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb75384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table by rosette for data and rand with percentage values\n",
    "dfs_by_rosetta = []\n",
    "\n",
    "for i in range(20):\n",
    "    rosetta_rows = []\n",
    "    rosetta_labels = []\n",
    "\n",
    "    for label, container in [(f\"Rosetta {i} data\", data_fractions),\n",
    "                             (f\"Rosetta {i} rand\", rand_fractions)]:\n",
    "        row = []\n",
    "        for t in structure_types:\n",
    "            fracs = container[i][t]\n",
    "            if len(fracs) == 0:\n",
    "                mean_frac = 0.0\n",
    "                std_frac = 0.0\n",
    "            else:\n",
    "                mean_frac = np.mean(fracs)\n",
    "                std_frac = np.std(fracs, ddof=1)\n",
    "\n",
    "            row.append(f\"{mean_frac*100:.2f}% ± {std_frac*100:.2f}%\")\n",
    "\n",
    "        rosetta_rows.append(row)\n",
    "        rosetta_labels.append(label)\n",
    "\n",
    "    df_rosetta = pd.DataFrame(rosetta_rows,\n",
    "                              columns=['Voids', 'Sheets', 'Filaments', 'Knots'],\n",
    "                              index=rosetta_labels)\n",
    "    dfs_by_rosetta.append(df_rosetta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92e8bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, rosetta_df in enumerate(dfs_by_rosetta):\n",
    "    print(f\"\\nRosetta {i}\")\n",
    "    display(rosetta_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada0ff56",
   "metadata": {},
   "source": [
    "# Entropy\n",
    "$\n",
    "H = - \\frac{1}{\\log_2 4} \\sum_{w=1}^4 p_w \\log_2(p_w)\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d47a91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "type_to_index = {t: i for i, t in enumerate(structure_types)}\n",
    "type_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479e0a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "entropy_per_rosetta = []\n",
    "\n",
    "for i in tqdm(range(20), desc=\"Rosettas\"):\n",
    "    df_real = df_typed_all[i][0]\n",
    "    df_real = df_real[df_real['RAN'] == False].copy()\n",
    "    n_points = len(df_real)\n",
    "\n",
    "    counts = np.zeros((n_points, 4), dtype=int)\n",
    "\n",
    "    for j in range(100):\n",
    "        df_j = df_typed_all[i][j]\n",
    "        if df_j is None:\n",
    "            continue\n",
    "\n",
    "        df_j_real = df_j[df_j['RAN'] == False].reset_index(drop=True)\n",
    "        types_j = df_j_real['TYPE'].values\n",
    "\n",
    "        # counter of the corresponding type for each point\n",
    "        for idx, t in enumerate(types_j):\n",
    "            if t in type_to_index:\n",
    "                t_idx = type_to_index[t] # index of the type\n",
    "                counts[idx, t_idx] += 1 # # add to that type's counter\n",
    "\n",
    "    entropy_list = []\n",
    "\n",
    "    # we go through each real point\n",
    "    for idx in range(n_points):\n",
    "        total = counts[idx].sum() # total times this point was ranked\n",
    "\n",
    "        # we calculate probabilities by type (p_w)\n",
    "        p_w = counts[idx] / total\n",
    "        # we calculate normalized Shannon entropy (we use only p > 0 to avoid log(0))\n",
    "        entropy = -np.sum(p_w[p_w > 0] * np.log2(p_w[p_w > 0])) / np.log2(4)\n",
    "\n",
    "        point = df_real.iloc[idx]\n",
    "        entropy_list.append({\n",
    "            'TARGETID': point['TARGETID'],\n",
    "            'ROSETTE_ID': i,\n",
    "            'ENTROPY': entropy\n",
    "        })\n",
    "\n",
    "    entropy_df = pd.DataFrame(entropy_list)\n",
    "    entropy_per_rosetta.append(entropy_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ec35d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(20):\n",
    "    df = entropy_per_rosetta[i]\n",
    "    entropy_values = df['ENTROPY'].dropna()\n",
    "\n",
    "    hist, bin_edges = np.histogram(entropy_values, bins=16, range=(0, 0.6), density=True)\n",
    "    bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2\n",
    "\n",
    "    plt.plot(bin_centers, hist, label=f'Rosetta {i}', linewidth=1.5)\n",
    "    plt.xlabel(\"Normalized Shannon Entropy\", fontsize=14)\n",
    "    plt.ylabel(\"PDF\", fontsize=14)\n",
    "    plt.grid(True)\n",
    "    plt.legend(loc='center left', fontsize=8)\n",
    "    plt.tight_layout()\n",
    "\n",
    "plt.title(\"QSO\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a70c35",
   "metadata": {},
   "source": [
    "# Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4f5b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_friends(first_id, all_ids, pair_ids, included_ids):\n",
    "    group = []\n",
    "    #print(first_id) \n",
    "    #print(all_ids)\n",
    "    loc = np.where(all_ids==first_id)[0][0]\n",
    "    #print('firstid', first_id, 'loc', loc)\n",
    "    if included_ids[loc] == 1: # caso base, el punto ya esta incluido\n",
    "        return group\n",
    "    else:\n",
    "        # si no esta incluido, lo incluyo\n",
    "        group.append(first_id)\n",
    "        included_ids[loc] = 1\n",
    "    \n",
    "        # ahora busco los amigos\n",
    "        friends = []\n",
    "        friends += list(pair_ids[pair_ids[:,0]==first_id,1])\n",
    "        friends += list(pair_ids[pair_ids[:,1]==first_id,0])\n",
    "        #print('friends', friends)\n",
    "        for friend in friends:\n",
    "            group.append(friend)\n",
    "            group.extend(find_friends(friend, all_ids, pair_ids, included_ids))\n",
    "    \n",
    "        group = list(set(group))\n",
    "        group.sort()\n",
    "        return group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc78186b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_fof_groups(pairs):\n",
    "    pairs = np.int_(pairs)\n",
    "    #print(pairs)\n",
    "    groups = {}\n",
    "    group_id = 0\n",
    "    all_ids = list(np.sort(np.unique(pairs.flatten())))\n",
    "    n_points = len(all_ids)\n",
    "    #print(n_points)\n",
    "    print('points to be grouped',n_points)\n",
    "    included_ids = list(np.zeros(n_points, dtype=int))\n",
    "\n",
    "    n_total = 0\n",
    "    for first_id in all_ids:\n",
    "        fof_ids = find_friends(first_id, all_ids, pairs, included_ids)\n",
    "        if len(fof_ids):\n",
    "            #if len(fof_ids)>8:\n",
    "            #    print(first_id, len(fof_ids))\n",
    "            n_total += len(fof_ids)\n",
    "            groups[group_id] = fof_ids\n",
    "            group_id += 1\n",
    "            \n",
    "    # sanity check\n",
    "    assert n_total == n_points\n",
    "    return groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf1d4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inertia_tensor(x, y, z):\n",
    "    x = x - np.mean(x)\n",
    "    y = y - np.mean(y)\n",
    "    z = z - np.mean(z)\n",
    "    r = np.sqrt(x**2 + y**2 + z**2)\n",
    "    I = np.ones((3,3))\n",
    "    \n",
    "    I[0,0] = np.sum(r**2 - x*x)\n",
    "    I[1,1] = np.sum(r**2 - y*y)\n",
    "    I[2,2] = np.sum(r**2 - z*z)\n",
    "    \n",
    "    I[0,1] = -np.sum(x*y)\n",
    "    I[1,0] = I[0,1]\n",
    "    \n",
    "    I[0,2] = -np.sum(x*z)\n",
    "    I[2,0] = I[0,2]\n",
    "    \n",
    "    I[1,2] = -np.sum(y*z)\n",
    "    I[2,1] = I[1,2]\n",
    "    \n",
    "    values, vectors = np.linalg.eig(I)\n",
    "    ii = np.argsort(-values)\n",
    "    #print(values[ii], len(x))\n",
    "    return np.sqrt(values[ii]), vectors[:,ii]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88602d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_group_properties(groups, positions):\n",
    "    props = {}\n",
    "    props['N'] = []\n",
    "    props['MEAN_X'] = []; props['MEAN_Y'] = []; props['MEAN_Z'] = []\n",
    "    props['SIGMA_X'] = []; props['SIGMA_Y'] = []; props['SIGMA_Z'] = []\n",
    "    props['SIGMA_R'] = []\n",
    "    props['LAMBDA_1'] = []; props['LAMBDA_2'] = []; props['LAMBDA_3'] = []\n",
    "    props['EIGEN_1'] = []; props['EIGEN_2'] = []; props['EIGEN_3'] = []\n",
    "    \n",
    "    for i in groups.keys():\n",
    "        x = positions[groups[i],0]\n",
    "        y = positions[groups[i],1]\n",
    "        z = positions[groups[i],2]\n",
    "        r = np.sqrt(x**2 + y**2 + z**2)\n",
    "        \n",
    "        if len(x)>4:\n",
    "        \n",
    "            props['N'].append(len(groups[i]))\n",
    "            props['SIGMA_R'].append(np.std(r))\n",
    "            props['MEAN_X'].append(np.mean(x))\n",
    "            props['MEAN_Y'].append(np.mean(y))\n",
    "            props['MEAN_Z'].append(np.mean(z))\n",
    "            props['SIGMA_X'].append(np.std(x))\n",
    "            props['SIGMA_Y'].append(np.std(y))\n",
    "            props['SIGMA_Z'].append(np.std(z))        \n",
    "\n",
    "            values, vectors = inertia_tensor(x,y,z)\n",
    "            props['LAMBDA_1'].append(values[0])\n",
    "            props['LAMBDA_2'].append(values[1])\n",
    "            props['LAMBDA_3'].append(values[2])\n",
    "            props['EIGEN_1'].append(vectors[:,0])\n",
    "            props['EIGEN_2'].append(vectors[:,1])\n",
    "            props['EIGEN_3'].append(vectors[:,2])\n",
    "\n",
    "    return pd.DataFrame(props)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70dad416",
   "metadata": {},
   "outputs": [],
   "source": [
    "rosetta_number = 0\n",
    "random_number = 99\n",
    "\n",
    "df_r1 = df_typed_all[rosetta_number][random_number]\n",
    "df_void_random = df_r1[(df_r1['RAN'] == False) & (df_r1['TYPE'] == 'filament')].reset_index(drop=True)\n",
    "\n",
    "positions = df_void_random[['X', 'Y', 'Z']].values\n",
    "n_points = len(positions)\n",
    "\n",
    "tri = Delaunay(positions)\n",
    "pairs = set()\n",
    "\n",
    "for simplex in tri.simplices:\n",
    "    for i, j in combinations(simplex, 2):\n",
    "        if i != j:\n",
    "            pairs.add(tuple(sorted((i, j))))\n",
    "pairs = np.array(list(pairs))\n",
    "\n",
    "groups = find_fof_groups(pairs)\n",
    "\n",
    "group_properties_df = compute_group_properties(groups, positions)\n",
    "\n",
    "group_properties_df \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
