{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170639b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial import Delaunay\n",
    "from sklearn.decomposition import PCA\n",
    "from itertools import combinations\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "from astropy.table import Table\n",
    "from collections import Counter\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import matplotlib.tri as mtri\n",
    "import matplotlib.cm as cm\n",
    "matplotlib.rcParams['figure.dpi'] = 360\n",
    "matplotlib.rcParams['text.usetex'] = True\n",
    "os.environ['PATH'] = '/Library/TeX/texbin:' + os.environ['PATH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f46aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_r(df):\n",
    "    coords = df[['X', 'Y', 'Z']].values\n",
    "    is_data = ~df['RAN'].values\n",
    "\n",
    "    tri = Delaunay(coords)\n",
    "\n",
    "    #! adjacency list for neighbors\n",
    "    neighbors = {i: set() for i in range(len(coords))}\n",
    "    for simplex in tri.simplices:\n",
    "        for i, j in combinations(simplex, 2):\n",
    "            neighbors[i].add(j)\n",
    "            neighbors[j].add(i)\n",
    "\n",
    "    r = np.zeros(len(coords), dtype=float)\n",
    "    for i, nbrs in neighbors.items():\n",
    "        n_data = int(np.sum(is_data[list(nbrs)]))\n",
    "        n_rand = len(nbrs) - n_data\n",
    "        if (n_data + n_rand) > 0:\n",
    "            r[i] = (n_data - n_rand) / (n_data + n_rand)\n",
    "        else:\n",
    "            raise ValueError(f'No neighbors for point {i} in the triangulation.')\n",
    "\n",
    "    out = df.copy()\n",
    "    out['r'] = r\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746a8e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_r(df):\n",
    "    r = df['r'].values\n",
    "    conds = [(r >= -1.0) & (r <= -0.9),\n",
    "             (r > -0.9) & (r <= 0.0),\n",
    "             (r > 0.0) & (r <= 0.9),\n",
    "             (r > 0.9) & (r <= 1.0),]\n",
    "    choices = ['void', 'sheet', 'filament', 'knot']\n",
    "    df = df.copy()\n",
    "    df['TYPE'] = np.select(conds, choices, default='error')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7360d7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reclassify_r(df):\n",
    "    r = df['r'].values\n",
    "    conds = [(r >= -1.0) & (r <= -0.5),\n",
    "             (r > -0.5) & (r <= 0.0),\n",
    "             (r > 0.0) & (r <= 0.9),\n",
    "             (r > 0.9) & (r <= 1.0)]\n",
    "    choices = ['void', 'sheet', 'filament', 'knot']\n",
    "    df = df.copy()\n",
    "    df['TYPE'] = np.select(conds, choices, default='error')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc13dff5",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d303f272",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ngc1 = Table.read(\"create_files/QSO_NGC1_clustering_data.ecsv\", format=\"ascii.ecsv\").to_pandas()\n",
    "data_ngc2 = Table.read(\"create_files/QSO_NGC2_clustering_data.ecsv\", format=\"ascii.ecsv\").to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf09df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ngc1['RAN'] = False\n",
    "data_ngc2['RAN'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbf6180",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\"\"\n",
    "output_dir = \"results_ASTRA_100\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "for zone_name, data_df in zip(['NGC_1', 'NGC_2'], [data_ngc1, data_ngc2]):\n",
    "    for j in tqdm(range(100), desc=f\"Proccesing {zone_name}\"):\n",
    "        rand_file = f\"data_100_random/{zone_name}_random_{j}.ecsv\"\n",
    "        output_file = os.path.join(output_dir, f\"{zone_name}_typed_{j}_TEST.parquet\")\n",
    "\n",
    "        if os.path.exists(output_file):\n",
    "            continue  # ya procesado\n",
    "\n",
    "        rand_df = Table.read(rand_file, format=\"ascii.ecsv\").to_pandas()\n",
    "        rand_df['RAN'] = True\n",
    "\n",
    "        df = pd.concat([data_df, rand_df], ignore_index=True)\n",
    "\n",
    "        df_r = compute_r(df)\n",
    "        df_typed = classify_r(df_r)\n",
    "\n",
    "        df_typed.to_parquet(output_file, index=False)\n",
    "\"\"\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5204576f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_type_xy_by_source(type_name, rand_id, zone,\n",
    "                           base_path=\"results_ASTRA_100\", point_size=0.1):\n",
    "\n",
    "    filename = f\"{base_path}/{zone}_typed_{rand_id}_TEST.parquet\"\n",
    "    df = pd.read_parquet(filename)\n",
    "\n",
    "    df_type = df[df['TYPE'] == type_name]\n",
    "\n",
    "    df_data = df_type[df_type['RAN'] == False]\n",
    "    df_rand = df_type[df_type['RAN'] == True]\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(df_rand['X'], df_rand['Y'], s=point_size, c='blue', alpha=0.5, label=f'Random (file {rand_id})')\n",
    "    #plt.scatter(df_data['X'], df_data['Y'], s=point_size, c='red', alpha=0.7, label='Data')\n",
    "\n",
    "\n",
    "    plt.title(f\"{type_name} - {zone}\", fontsize=13)\n",
    "    plt.xlabel(\"X [Mpc]\", fontsize=12)\n",
    "    plt.ylabel(\"Y [Mpc]\", fontsize=12)\n",
    "    plt.legend(fontsize=7)\n",
    "    #plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.gca().set_aspect('equal', adjustable='box')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31977c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_type_xy_by_source('void', 78, zone='NGC_1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e07e9c",
   "metadata": {},
   "source": [
    "# Type classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e188b757",
   "metadata": {},
   "outputs": [],
   "source": [
    "structure_types = ['void', 'sheet', 'filament', 'knot']\n",
    "zones = ['NGC_1', 'NGC_2'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7f07cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_fractions = {zone: {t: [] for t in structure_types} for zone in zones}\n",
    "rand_fractions = {zone: {t: [] for t in structure_types} for zone in zones}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4592a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "for zone in zones:\n",
    "    for j in range(100):\n",
    "        filepath = f\"results_ASTRA_100/{zone}_typed_{j}.parquet\"\n",
    "        df = pd.read_parquet(filepath)\n",
    "\n",
    "        for source, container in [(False, data_fractions), (True, rand_fractions)]:\n",
    "            df_sub = df[df['RAN'] == source]\n",
    "            total = len(df_sub)\n",
    "\n",
    "            for t in structure_types:\n",
    "                count = np.sum(df_sub['TYPE'] == t)\n",
    "                frac = count / total if total > 0 else 0.0\n",
    "                container[zone][t].append(frac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e057ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_by_zone = []\n",
    "\n",
    "mean_data_by_type = {t: [] for t in structure_types}\n",
    "mean_rand_by_type = {t: [] for t in structure_types}\n",
    "\n",
    "for zone in zones:\n",
    "    zone_rows = []\n",
    "    zone_labels = []\n",
    "\n",
    "    for label, container, store in [(f\"{zone} data\", data_fractions, mean_data_by_type),\n",
    "                                     (f\"{zone} rand\", rand_fractions, mean_rand_by_type)]:\n",
    "        row = []\n",
    "        for t in structure_types:\n",
    "            fracs = container[zone][t]\n",
    "            if len(fracs) == 0:\n",
    "                mean_frac = 0.0\n",
    "                std_frac = 0.0\n",
    "            else:\n",
    "                mean_frac = np.mean(fracs)\n",
    "                std_frac = np.std(fracs, ddof=1)\n",
    "\n",
    "            store[t].append(mean_frac)\n",
    "            row.append(f\"{mean_frac*100:.2f}% ± {std_frac*100:.2f}%\")\n",
    "\n",
    "        zone_rows.append(row)\n",
    "        zone_labels.append(label)\n",
    "\n",
    "    df_zone = pd.DataFrame(zone_rows,\n",
    "                           columns=['Voids', 'Sheets', 'Filaments', 'Knots'],\n",
    "                           index=zone_labels)\n",
    "    dfs_by_zone.append(df_zone)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568db5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_by_zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92e8bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_rows = []\n",
    "\n",
    "for label, store in [(\"Mean data\", mean_data_by_type),\n",
    "                     (\"Mean rand\", mean_rand_by_type)]:\n",
    "    row = []\n",
    "    for t in structure_types:\n",
    "        means = store[t]  # a list of two values (NGC1 and NGC2)\n",
    "        avg = np.mean(means)\n",
    "        err = np.std(means, ddof=1)\n",
    "        row.append(f\"{avg*100:.2f}% ± {err*100:.5f}%\")\n",
    "    summary_rows.append(row)\n",
    "\n",
    "df_summary = pd.DataFrame(summary_rows,\n",
    "                          columns=['Voids', 'Sheets', 'Filaments', 'Knots'],\n",
    "                          index=['Mean data', 'Mean rand'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b40e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada0ff56",
   "metadata": {},
   "source": [
    "# Entropy\n",
    "$\n",
    "H = - \\frac{1}{\\log_2 4} \\sum_{w=1}^4 p_w \\log_2(p_w)\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7082978",
   "metadata": {},
   "outputs": [],
   "source": [
    "type_to_index = {t: i for i, t in enumerate(structure_types)}\n",
    "type_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24eb1c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"results_ASTRA_100\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29ebde7",
   "metadata": {},
   "outputs": [],
   "source": [
    "entropy_per_zone = []\n",
    "\n",
    "for zone in tqdm(zones, desc=\"Regions\"):\n",
    "\n",
    "    # reference of real points \n",
    "    df_real = pd.read_parquet(f\"{base_path}/{zone}_typed_0.parquet\")\n",
    "    df_real = df_real[df_real['RAN'] == False].copy().reset_index(drop=True)\n",
    "    n_points = len(df_real)\n",
    "\n",
    "    # rows = real points, columns = types\n",
    "    counts = np.zeros((n_points, 4), dtype=int)\n",
    "\n",
    "    for j in tqdm(range(100), desc=f\"{zone} - Files\"):\n",
    "        df_j = pd.read_parquet(f\"{base_path}/{zone}_typed_{j}.parquet\")\n",
    "        df_j_real = df_j[df_j['RAN'] == False].reset_index(drop=True)\n",
    "        types_j = df_j_real['TYPE'].values\n",
    "\n",
    "        for idx, t in enumerate(types_j):\n",
    "            if t in type_to_index:\n",
    "                t_idx = type_to_index[t]\n",
    "                counts[idx, t_idx] += 1\n",
    "\n",
    "    # Calculate entropy for each point\n",
    "    entropy_list = []\n",
    "\n",
    "    for idx in range(n_points):\n",
    "        total = counts[idx].sum()\n",
    "        p_w = counts[idx] / total if total > 0 else np.zeros(4)\n",
    "        entropy = -np.sum(p_w[p_w > 0] * np.log2(p_w[p_w > 0])) / np.log2(4)\n",
    "\n",
    "        point = df_real.iloc[idx]\n",
    "        entropy_list.append({\n",
    "            'TARGETID': point['TARGETID'],\n",
    "            'ZONE': zone,\n",
    "            'ENTROPY': entropy\n",
    "        })\n",
    "\n",
    "    entropy_df = pd.DataFrame(entropy_list)\n",
    "    entropy_per_zone.append(entropy_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8a60af",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('entropy_per_rosetta.pkl', 'rb') as f:\n",
    "    entropy_per_rosetta = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c30253",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))  \n",
    "\n",
    "# Rosetta\n",
    "for i in range(20):\n",
    "    df = entropy_per_rosetta[i]\n",
    "    entropy_values = df['ENTROPY']\n",
    "\n",
    "    hist, bin_edges = np.histogram(entropy_values, bins=16, range=(0, 0.6), density=True)\n",
    "    bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2\n",
    "\n",
    "    if i == 0:\n",
    "        plt.plot(bin_centers, hist, label='Rosettas',\n",
    "                 color='grey', linewidth=0.5, linestyle='--')\n",
    "    else:\n",
    "        plt.plot(bin_centers, hist,\n",
    "                 color='grey', linewidth=0.5, linestyle='--')  \n",
    "\n",
    "# Zones\n",
    "colors = ['blue', 'red'] \n",
    "\n",
    "for i, df in enumerate(entropy_per_zone):\n",
    "    zone_name = df['ZONE'].iloc[0]  \n",
    "    entropy_values = df['ENTROPY']\n",
    "\n",
    "    hist, bin_edges = np.histogram(entropy_values, bins=16, range=(0, 0.6), density=True)\n",
    "    bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2\n",
    "\n",
    "    plt.plot(bin_centers, hist, label=f'{zone_name}', \n",
    "             color=colors[i], linewidth=1.5)\n",
    "    \n",
    "plt.xlabel(\"Normalized Shannon Entropy\", fontsize=14)\n",
    "plt.ylabel(\"PDF\", fontsize=14)\n",
    "plt.grid(True)\n",
    "plt.legend(loc='center left', fontsize=8, bbox_to_anchor=(1, 0.5)) \n",
    "plt.title(\"QSO\", fontsize=15)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a70c35",
   "metadata": {},
   "source": [
    "# Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8aba97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import cKDTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3487561",
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_fof_groups(zone, rand_id, type_name, source='data', linking_length=5.0, base_path=\"results_ASTRA_100\"):\n",
    "    # 1. Cargar el archivo\n",
    "    filename = f\"{base_path}/{zone}_typed_{rand_id}.parquet\"\n",
    "    df = pd.read_parquet(filename)\n",
    "\n",
    "    # 2. Filtrar por tipo\n",
    "    df = df[df['TYPE'] == type_name]\n",
    "\n",
    "    # 3. Filtrar por fuente\n",
    "    if source == 'data':\n",
    "        df = df[df['RAN'] == False]\n",
    "    elif source == 'random':\n",
    "        df = df[df['RAN'] == True]\n",
    "    elif source == 'both':\n",
    "        pass  # No filtramos RAN\n",
    "    else:\n",
    "        raise ValueError(\"source debe ser 'data', 'random' o 'both'\")\n",
    "\n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "    if len(df) == 0:\n",
    "        print(\"No hay puntos con ese criterio.\")\n",
    "        return df\n",
    "\n",
    "    # 4. Aplicar Friends-of-Friends (FoF) con KDTree\n",
    "    positions = df[['X', 'Y', 'Z']].values\n",
    "    tree = cKDTree(positions)\n",
    "    pairs = tree.query_pairs(r=linking_length)\n",
    "\n",
    "    # 5. Construir grupos (componentes conexas)\n",
    "    parent = list(range(len(positions)))\n",
    "\n",
    "    def find(i):\n",
    "        while parent[i] != i:\n",
    "            parent[i] = parent[parent[i]]\n",
    "            i = parent[i]\n",
    "        return i\n",
    "\n",
    "    def union(i, j):\n",
    "        ri, rj = find(i), find(j)\n",
    "        if ri != rj:\n",
    "            parent[ri] = rj\n",
    "\n",
    "    for i, j in pairs:\n",
    "        union(i, j)\n",
    "\n",
    "    # Asignar group_id\n",
    "    group_ids = np.array([find(i) for i in range(len(positions))])\n",
    "    _, group_ids = np.unique(group_ids, return_inverse=True)\n",
    "    df['group_id'] = group_ids\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749329e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filament_groups = identify_fof_groups('NGC_1', 7, 'filament', source='data', linking_length=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17f9113",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_top_n_groups(df, n=3, point_size=0.01):\n",
    "\n",
    "    # obtain the N groups with the most points\n",
    "    top_ids = df['group_id'].value_counts().head(n).index.tolist()\n",
    "\n",
    "    colors = plt.cm.tab20(np.linspace(0, 1, n)) \n",
    "\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    for group_id, color in zip(top_ids, colors):\n",
    "        subset = df[df['group_id'] == group_id]\n",
    "        plt.scatter(subset['X'], subset['Y'], s=point_size, label=f'Group {group_id}')\n",
    "\n",
    "    plt.xlabel(\"X [Mpc]\")\n",
    "    plt.ylabel(\"Y [Mpc]\")\n",
    "    #plt.legend(fontsize=8)\n",
    "    #plt.grid(True)\n",
    "    plt.gca().set_aspect('equal', adjustable='box')\n",
    "    plt.tight_layout()\n",
    "    plt.gca().set_aspect('equal', adjustable='box')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ddb54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_filament_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31233fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_top_n_groups(df_filament_groups[df_filament_groups['group_id'] != 9492], n=100)\n",
    "plot_top_n_groups(df_filament_groups, n=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ccd7b0d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
